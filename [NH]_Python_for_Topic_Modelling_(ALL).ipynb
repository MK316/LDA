{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsnam95/my/blob/main/%5BNH%5D_Python_for_Topic_Modelling_(ALL).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import matplotlib.pyplot as plt\n",
        "import gensim\n",
        "from gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel\n",
        "from gensim.corpora import Dictionary"
      ],
      "metadata": {
        "id": "T2lVWFpepB0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "7ISD7OhipXVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_news = pd.read_csv(\"a-machado-(CLEAN)-Revisado3-(solo libros)-nuevo.csv\")"
      ],
      "metadata": {
        "id": "R_D20tWdpo8H"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 정제"
      ],
      "metadata": {
        "id": "-mb3bXQGqk21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "black_list = [\n",
        "                                  \"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\", # 개별 알파벳(alfabeto) \n",
        "                                       \n",
        "                                 \"al\", \"del\",\"de\",\"en\", \"hacia\", \"por\", \"para\", \"entre\",'sobre','según', #전치사(preposiciones)\n",
        "                                 \"con\",\"comigo\",\"contigo\", \"consigo\", \"sin\",\n",
        "\n",
        "                                 'cual', 'cuál', 'cuales', 'cuáles', 'cualquier', 'cualquiera', 'cualquieras', #관계사(relativos) & 의문사(interrogativos) (2)\n",
        "                                 'cuan', 'cuán', 'cuando', 'cuándo', 'cuanta','cuánta', 'cuantas', 'cuántas', 'cuanto', 'cuánto', 'cuantos', 'cuántos',   #관계사(relativos) & 의문사(interrogativos) (1)\n",
        "                                 'donde', 'dónde', 'adonde', 'adónde','como', 'cómo',                                  #관계사(relativos) & 의문사(interrogativos) (3)\n",
        "                                 'que', 'qué', 'quien', 'quién', 'quienes', 'quiénes','quienesquiera', 'quienquiera', #관계사(relativos) & 의문사(interrogativos) (4)\n",
        "                                 'cuyo', 'cuya','cuyos','cuyas', #관계사(relativos) & 의문사(interrogativos) (4)   \n",
        "\n",
        "                                 'el', 'la', 'las', 'le', 'les', 'lo', 'los', 'un', 'una', 'unas', 'uno', 'unos', #관사(articulos)\n",
        "                                 'yo', 'me', 'mi', 'mí', 'mia', 'mía', 'mias', 'mías','mio','mío', 'mios', 'míos', 'mis', #대명사(prombres)-1S\n",
        "                                 'nos', 'nosotras', 'nosotros', 'nuestra', 'nuestras', 'nuestro', 'nuestros', #대명사(prombres)-1P\n",
        "                                 'vosotras', 'vosotros', 'vuestra', 'vuestras', 'vuestro', 'vuestros', 'os', #대명사(prombres)-2P\n",
        "                                 'él', 'ella', 'ellas', 'ello', 'ellos', #대명사(prombres)-3S (1)\n",
        "                                 'ud', 'uds', 'usted','ustedes', 'vd', 'vds', 'se', 'su', 'sus', 'suya', 'suyas', 'suyo', 'suyos', #대명사(prombres)-3S (2)\n",
        "                                 'te', 'ti', 'tí', 'tu', 'tú', 'tus', 'tuya', 'tuyas', 'tuyo', 'tuyos', #대명사(prombres)-2S\n",
        "\n",
        "                                 #'este', 'esta', 'estos', 'estas', 'ese', 'esa', 'esos', 'esas','aquel', 'aquella', 'aquellos', 'aquellas', #지시사(demostrativos)\n",
        "\n",
        "                                 'era', 'erais', 'eramos', 'éramos', 'eran', 'eras',  #SER 동사활용형(1)\n",
        "                                 'eres', 'es', 'sea', 'seáis', 'seamos', 'sean', 'seas','sois', 'somos','son', 'soy', #SER 동사활용형(2)\n",
        "                                 'fue', 'fué', 'fui', 'fuí', 'fuimos', 'fuiste', 'fuisteis', #SER 동사활용형(3)\n",
        "                                 'fuera', 'fuerais', 'fuéramos', 'fueran', 'fueras', 'fueron', 'fuese', 'fueseis', 'fuésemos','fuesen', 'fueses', #SER 동사활용형(4)\n",
        "                                 'será', 'serán', 'serás', 'seré', 'seréis', 'seremos', #SER 동사활용형(5)\n",
        "                                 'sería', 'seríais', 'seríamos', 'serían', 'serías', #SER 동사활용형(6)\n",
        "                                 'sido', 'siendo', #SER 동사활용형(7)\n",
        "\n",
        "                                 'estar', 'está', 'estais', 'estáis', 'estamos', 'estan', 'están','estás', 'estoy',  #ESTAR 동사활용형(1)\n",
        "                                 'estaba', 'estabais', 'estábamos', 'estaban', 'estabas', #ESTAR 동사활용형(2)\n",
        "                                 'estada', 'estadas', 'estando', 'estad', #ESTAR 동사활용형(3)\n",
        "                                 'estará', 'estarán', 'estarás', 'estaré', 'estaréis', 'estaremos', #ESTAR 동사활용형(4)\n",
        "                                 'estaría', 'estaríais', 'estaríamos', 'estarían', 'estarías', #ESTAR 동사활용형(5)\n",
        "                                 'esté', 'estéis', 'estemos', 'estén', 'estés', #ESTAR 동사활용형(6) \n",
        "                                 'estuve', 'estuviera', 'estuvierais', 'estuviéramos', 'estuvieran', 'estuvieras', 'estuvieron', #ESTAR 동사활용형(7)\n",
        "                                 'estuviese', 'estuvieseis', 'estuviésemos', 'estuviesen', 'estuvieses', 'estuvimos', 'estuviste', 'estuvisteis', 'estuvo',  #ESTAR 동사활용형(8)\n",
        "\n",
        "                                 'haber', 'ha', 'habéis', 'han', 'has', 'hay', 'he', 'hemos',  #HABER 동사활용형(1)\n",
        "                                 'habia', 'había', 'habíais', 'habíamos', 'habían', 'habías',  #HABER 동사활용형(2)\n",
        "                                 'habida', 'habidas', 'habido', 'habidos', 'habiendo',         #HABER 동사활용형(3)\n",
        "                                 'habrá', 'habrán', 'habrás', 'habré', 'habréis', 'habremos',  #HABER 동사활용형(4)\n",
        "                                 'habría', 'habríais', 'habríamos', 'habrían', 'habrías',      #HABER 동사활용형(5)\n",
        "                                 'haya', 'hayáis', 'hayamos', 'hayan', 'hayas',                #HABER 동사활용형(6)\n",
        "                                 'hube', 'hubimos', 'hubiste', 'hubisteis', 'hubo',            #HABER 동사활용형(7)\n",
        "                                 'hubiera', 'hubierais', 'hubiéramos', 'hubieran', 'hubieras', 'hubieron',  #HABER 동사활용형(8) \n",
        "                                 'hubiese', 'hubieseis', 'hubiésemos', 'hubiesen', 'hubieses', #HABER 동사활용형(9) \n",
        "\n",
        "                                 'ni','no','jamás','nunca','nada','ningún','ninguna','ninguno', #부정어(negativos)\n",
        "                                 'pero','mas', 'aunque','pues','porque','si','sí', #접속사(conjunciones)\n",
        "                                 'algo','algún','alguna','algunas','alguno','algunos', #부정어(indefinidos)\n",
        "                                 'embargo',                                     #기타(etc)                                                                   ))         \n",
        "  \n",
        "                                   \"LBR\",\n",
        "                                   \"ttl\",\n",
        "                                   \"mtl\",\n",
        "                                   \"ftl\",\n",
        "                                   \"=\",\"===============================================\",\n",
        "                                   \"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\"]"
      ],
      "metadata": {
        "id": "fQXEpuoHqKMR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop = set(stopwords.words('spanish'))\n",
        "additional_stopwords=set(black_list)\n",
        "stopwords = stop.union(additional_stopwords)"
      ],
      "metadata": {
        "id": "HvdtnQJeq98_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "!python -m spacy download es_core_news_sm\n",
        "nlp = spacy.load(\"es_core_news_sm\")"
      ],
      "metadata": {
        "id": "HTiSGf6_rEDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatization(texts):\n",
        "    texts_out = [token.text for token in nlp(texts) if token.text not in black_list and len(token.text)>2]\n",
        "    return texts_out"
      ],
      "metadata": {
        "id": "2d9a8dBznPUd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect phrases, based on collected collocation counts. Adjacent words that appear together more frequently than expected are joined together with the _ character.\n",
        "bigram = gensim.models.Phrases(df_news.texto.to_list())"
      ],
      "metadata": {
        "id": "HZXpUnfi6dOq"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cleaner(word):\n",
        "  word = re.sub(r'((http|https)\\:\\/\\/)?[a-zA-Z0-9\\.\\/\\?\\:@\\-_=#]+\\.([a-zA-Z]){2,6}([a-zA-Z0-9\\.\\&\\/\\?\\:@\\-_=#])*', '', word, flags=re.MULTILINE)\n",
        "  word = re.sub(r'(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', \"\", word)\n",
        "  word = re.sub(r'ee.uu', 'eeuu', word)\n",
        "  word = re.sub(r'\\#\\.', '', word)\n",
        "  word = re.sub(r'\\n', '', word)\n",
        "  word = re.sub(r',', '', word)\n",
        "  word = re.sub(r'\\-', ' ', word)\n",
        "  word = re.sub(r'\\.{3}', ' ', word)\n",
        "  word = re.sub(r'a{2,}', 'a', word)\n",
        "  word = re.sub(r'é{2,}', 'é', word)\n",
        "  word = re.sub(r'i{2,}', 'i', word)\n",
        "  word = re.sub(r'ja{2,}', 'ja', word) \n",
        "  word = re.sub(r'á', 'a', word)\n",
        "  word = re.sub(r'é', 'e', word)\n",
        "  word = re.sub(r'í', 'i', word)\n",
        "  word = re.sub(r'ó', 'o', word)\n",
        "  word = re.sub(r'ú', 'u', word)  \n",
        "  word = re.sub('[^a-zA-Z]', ' ', word)\n",
        "  list_word_clean = []\n",
        "  for w1 in word.split(\" \"):\n",
        "    if  w1.lower() not in stopwords:\n",
        "      list_word_clean.append(w1.lower())\n",
        "\n",
        "  # 재조합해서 lemmatize한 list\n",
        "  out_text = lemmatization(\" \".join(bigram_list))\n",
        "  return out_text"
      ],
      "metadata": {
        "id": "n_3wAGvHnTSW"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_news['texto2'] = df_news['texto']\n",
        "df_news['texto'] = df_news['texto'].apply(cleaner)"
      ],
      "metadata": {
        "id": "WzlZ8FlLrcDt"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now we need to build the corpus used in gensim"
      ],
      "metadata": {
        "id": "cIosAjhsrdd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = Dictionary(df_news['texto'].to_list())\n",
        "dictionary.compactify() #??\n",
        "# Filter extremes\n",
        "dictionary.filter_extremes(no_below=2, no_above=0.97, keep_n=None)\n",
        "dictionary.compactify() #??\n",
        "\n",
        "corpus = [dictionary.doc2bow(text) for text in df_news['texto'].to_list()]"
      ],
      "metadata": {
        "id": "MoqHmNhHre5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Model#1: Hierarchical Dirichlet process Model**"
      ],
      "metadata": {
        "id": "v_lMuA4XrnXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "time.clock = time.time"
      ],
      "metadata": {
        "id": "X1B7Nq35rtpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hdpmodel = HdpModel(corpus=corpus, id2word=dictionary, random_state= 30)"
      ],
      "metadata": {
        "id": "SHG7hYxCr3YD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "260d1b46-f357-4af4-9fcc-f7873dac0196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "and the topics of this model:"
      ],
      "metadata": {
        "id": "GuuXoNTxr5HZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_topics(model, model_type=\"lda\"):\n",
        "  for topic_idx, topic in enumerate(model.print_topics()):\n",
        "    print (\"Topic %d:\" % (topic_idx))\n",
        "    if model_type== \"hdp\":\n",
        "      print (\" \".join(re.findall( r'\\*(.[^\\*-S]+).?', topic[1])), \"\\n\")\n",
        "    else:\n",
        "      print (\" \".join(re.findall( r'\\\"(.[^\"]+).?', topic[1])), \"\\n\")"
      ],
      "metadata": {
        "id": "mysUf0HEr6-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hdpmodel.show_topics() \n",
        "\n",
        "display_topics(hdpmodel, model_type=\"hdp\")"
      ],
      "metadata": {
        "id": "kc_QDr6WsMkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "as we could see there are 20 topics, however is kind of dificult to interpret or follow, so we decide to move to another model."
      ],
      "metadata": {
        "id": "7fRJg9XIr8Ji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Model#2: LSI Model**"
      ],
      "metadata": {
        "id": "dSdNRkzwruDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_graph(dictionary, corpus, texts, limit, model):\n",
        "    \"\"\"\n",
        "    Function to display num_topics - LDA graph using c_v coherence\n",
        "    \n",
        "    Parameters:\n",
        "    ----------\n",
        "    dictionary : Gensim dictionary\n",
        "    corpus : Gensim corpus\n",
        "    limit : topic limit\n",
        "    \n",
        "    Returns:\n",
        "    -------\n",
        "    lm_list : List of LDA topic models\n",
        "    c_v : Coherence values corresponding to the LDA model with respective number of topics\n",
        "    \"\"\"\n",
        "    c_v = []\n",
        "    lm_list = []\n",
        "    for num_topics in range(1, limit):\n",
        "        if model == 'lsi':\n",
        "          lm = LsiModel(corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
        "        else:\n",
        "          lm = LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
        "        lm_list.append(lm)\n",
        "        cm = CoherenceModel(model=lm, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        c_v.append(cm.get_coherence())\n",
        "        \n",
        "    # Show graph\n",
        "    x = range(1, limit)\n",
        "    plt.plot(x, c_v)\n",
        "    plt.xlabel(\"num_topics\")\n",
        "    plt.ylabel(\"Coherence score\")\n",
        "    plt.legend((\"c_v\"), loc='best')\n",
        "    plt.show()\n",
        "    \n",
        "    return lm_list, c_v"
      ],
      "metadata": {
        "id": "bJZNVNLpr77U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lsimodel = LsiModel(corpus=corpus, num_topics=10, id2word=dictionary)"
      ],
      "metadata": {
        "id": "ASKrD_d4ru3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_topics(lsimodel)  # Showing the topics"
      ],
      "metadata": {
        "id": "S1M6X0SFsRc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seen that with 10 topics there is some themes with keywords related to: trump, venezuela, police, electiones, terrorism; still is a little difficult to gt some insight, because of this we are trying to select the best number of topics by iterate over a range of values and looking the coherence."
      ],
      "metadata": {
        "id": "Zs5Dmy8MsS9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lmlist_lsi, c_v = evaluate_graph(dictionary=dictionary, corpus=corpus, texts=df_news['texto'].to_list(), limit=21, model= \"lsi\") #HY: text -> texto"
      ],
      "metadata": {
        "id": "4ejOEzZdsfvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the coherence the best number of topics are between 3-7, however you must select the topics using both the coherence and visual inspection."
      ],
      "metadata": {
        "id": "5Avv8IO7sia5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display_topics(lmlist_lsi[8])"
      ],
      "metadata": {
        "id": "oysyAPPrskTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, Let's try another model!"
      ],
      "metadata": {
        "id": "XV78W8jXsVkV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Model#3: Latent Dirichlet Allocation Model**"
      ],
      "metadata": {
        "id": "xCQopweArvSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ldamodel = LdaModel(corpus=corpus, num_topics=10, id2word=dictionary)"
      ],
      "metadata": {
        "id": "yjux73SDrwcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_topics(ldamodel)"
      ],
      "metadata": {
        "id": "Nsxk56oVsoVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find out the optimal number of topics for the LDA model based on the coherence metric:"
      ],
      "metadata": {
        "id": "YhF7YmIjsox0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lmlist, c_v = evaluate_graph(dictionary=dictionary, corpus=corpus, texts=df_news['texto'].to_list(), limit=21, model= \"lda\")"
      ],
      "metadata": {
        "id": "nu3IgpL6sqjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this model it seems that 9 or 18, again we must to check the keywords too."
      ],
      "metadata": {
        "id": "CclenWNKssXw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Comparing the Model Coherence of the Best Models**"
      ],
      "metadata": {
        "id": "Ik-yrJhTsu6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ldamodel = lmlist[5]\n",
        "lsimodel = lmlist_lsi[2]\n",
        "\n",
        "lsitopics = [[word for word, prob in topic] for topicid, topic in lsimodel.show_topics(formatted=False)]\n",
        "\n",
        "hdptopics = [[word for word, prob in topic] for topicid, topic in hdpmodel.show_topics(formatted=False)]\n",
        "\n",
        "ldatopics = [[word for word, prob in topic] for topicid, topic in ldamodel.show_topics(formatted=False)]"
      ],
      "metadata": {
        "id": "H2VUKYGosy72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lsi_coherence = CoherenceModel(topics=lsitopics[:10], texts=df_news['texto'].to_list(), dictionary=dictionary, window_size=10).get_coherence() #HY: text -> texto\n",
        "\n",
        "hdp_coherence = CoherenceModel(topics=hdptopics[:10], texts=df_news['texto'].to_list(), dictionary=dictionary, window_size=10).get_coherence() #HY: text -> texto\n",
        "\n",
        "lda_coherence = CoherenceModel(topics=ldatopics, texts=df_news['texto'].to_list(), dictionary=dictionary, window_size=10).get_coherence() #HY: text -> texto"
      ],
      "metadata": {
        "id": "YyicIxDts0LC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "coherences = [lsi_coherence, hdp_coherence, lda_coherence]\n",
        "n = len(coherences)\n",
        "x = ['lsi_coherence','hdp_coherence', 'lda_coherence']\n",
        "sns.barplot(x, coherences)\n"
      ],
      "metadata": {
        "id": "ioSpCKlKs2E4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "dcb61248-3143-4f90-e5e8-45f9cd5edf0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the **LdaModel** model **with 8 topics** has the higher value of\n",
        "coherence ?????? **[HY: 실제 결과에 따라 수정 필요]**"
      ],
      "metadata": {
        "id": "PZvMKdJts3o-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Examine the keyword to get the topics of the best model"
      ],
      "metadata": {
        "id": "DZPL5Osus9TX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display_topics(ldamodel)"
      ],
      "metadata": {
        "id": "M_eiibhUs-d9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let´s check the keyword when we selecting another number of topics (14)"
      ],
      "metadata": {
        "id": "hceAuHSFtP3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ldamodel_16 =lmlist[16]"
      ],
      "metadata": {
        "id": "E5voqDNXtSpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_topics(ldamodel_16)"
      ],
      "metadata": {
        "id": "d7wm18zVtT-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Classifiying all documents**\n",
        "\n",
        "*  now that we have been select the best model and topics number, is time to assign a topic to each document, means cluster according to the topics\n",
        "\n"
      ],
      "metadata": {
        "id": "hRdD9frctVus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_topics_sentences(ldamodel=0, corpus=corpus, texts=0):\n",
        "    # Init output\n",
        "    sent_topics_df = pd.DataFrame()-n\n",
        "\n",
        "    # Get main topic in each document\n",
        "    for i, row in enumerate(ldamodel[corpus]):\n",
        "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
        "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
        "        for j, (topic_num, prop_topic) in enumerate(row):\n",
        "            if j == 0:  # => dominant topic\n",
        "                wp = ldamodel.show_topic(topic_num)\n",
        "                topic_keywords = \", \".join([word for word, prop in wp])\n",
        "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
        "            else:\n",
        "                break\n",
        "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
        "\n",
        "    # Add original text to the end of the output\n",
        "    contents = pd.Series(texts)\n",
        "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
        "    return(sent_topics_df)\n",
        "\n",
        "\n",
        "df_topic_sents_keywords = format_topics_sentences(ldamodel, corpus=corpus, texts=df_news['texto'].to_list()) #HY: text -> texto"
      ],
      "metadata": {
        "id": "1GIyFKV4te4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Format\n",
        "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
        "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
        "\n",
        "# Show\n",
        "df_dominant_topic.head(500)"
      ],
      "metadata": {
        "id": "dtTKmIW1tgG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We selected the ldamodel with 12 topics and asigned a dominant topic to each document, now let map each topic with a label "
      ],
      "metadata": {
        "id": "hwQ9x2rBthmK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "first let's create the dictionary"
      ],
      "metadata": {
        "id": "-UlgNzJytkn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_dicc = {0:'TEMA1', 1:'TEMA2', 2:'TEMA3', 3: 'TEMA4', 4:'TEMA5', 5:'TEMA6', 6:'TEMA7', \n",
        "              7:'TEMA8', 8:'TEMA9', 9: 'TEMA10', 10:'TEMA11', 11:'TEMA12'}   #HY: 다시 설정 필요!!"
      ],
      "metadata": {
        "id": "66DsHVBOtiQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dominant_topic['Dominant_Topic'] = df_dominant_topic['Dominant_Topic'].astype('int64')"
      ],
      "metadata": {
        "id": "zLtttUbmton-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dominant_topic['Dominant_Topic'] = df_dominant_topic['Dominant_Topic'].map(label_dicc)\n",
        "#df_dominant_topic.head(10)\n",
        "df_dominant_topic"
      ],
      "metadata": {
        "id": "sTZd2n-JtqLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_news['labels'] = df_dominant_topic['Dominant_Topic']"
      ],
      "metadata": {
        "id": "te0icoK0tqlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's examine some text and its topics."
      ],
      "metadata": {
        "id": "Mufi6S8ltsNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df_news[['texto2', 'labels']].head(10)\n",
        "df_news[['texto2', 'labels']]"
      ],
      "metadata": {
        "id": "u0QGKVmVtuZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_news[ df_news['labels'] == 'family'].head().texto2 #HY: text -> texto\n",
        "df_news[ df_news['labels'] == 'TEMA5'].head().texto2 #HY: text -> texto"
      ],
      "metadata": {
        "id": "rVm-DEq9tv0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's see the distribution of topics.**"
      ],
      "metadata": {
        "id": "05B66e98txav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ax = df_dominant_topic['Dominant_Topic'].value_counts().plot(kind='bar')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iLLKhG7wt39F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The topis are almost balanced, so we are good"
      ],
      "metadata": {
        "id": "0cd5OnF1t6IE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "finally that we have our models set up, as well as analyzed, we can go ahead to visualizing them."
      ],
      "metadata": {
        "id": "hAeUQrHXt8ce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyLDAvis"
      ],
      "metadata": {
        "id": "LAYmBzj5uzNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyLDAvis\n",
        "pyLDAvis.enable_notebook()"
      ],
      "metadata": {
        "id": "G4bc0HDGu1IC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyLDAvis.gensim\n",
        "pyLDAvis.gensim.prepare(ldamodel, corpus, dictionary)"
      ],
      "metadata": {
        "id": "uRubllieu2jZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}